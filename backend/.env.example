# Taxi Fare Prediction API - Environment Configuration
# Copy this file to .env and update the values as needed
# Updated for Render deployment support

# Application Environment
ENVIRONMENT=production
DEBUG=false
LOG_LEVEL=info

# Server Configuration (Render will provide PORT automatically)
HOST=0.0.0.0
PORT=8000
WORKERS=2

# CORS Configuration (comma-separated list) - Update with your Render frontend URL
CORS_ORIGINS=https://taxi-fare-frontend.onrender.com,http://localhost:3000,http://127.0.0.1:3000

# Model Configuration
MODEL_PATH=./models/best_taxi_fare_model.pkl
PROCESSOR_PATH=./models/feature_processor.pkl
METADATA_PATH=./models/final_model_metadata.json

# Performance Settings
MAX_PREDICTION_TIME=5.0
CACHE_PREDICTIONS=true
CACHE_TTL=300

# Monitoring Settings
ENABLE_METRICS=true
METRICS_PATH=/metrics
HEALTH_CHECK_PATH=/health

# Logging Configuration
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_FILE=

# Security Settings
ALLOWED_HOSTS=*
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# Python Settings (for Render deployment)
PYTHONPATH=/opt/render/project/src
PYTHONUNBUFFERED=1
PYTHONDONTWRITEBYTECODE=1

# Database Configuration (for future use)
# DATABASE_URL=postgresql://user:password@host:port/database

# Redis Configuration (for future caching)
# REDIS_URL=redis://host:port/0

# API Keys (if needed)
# EXTERNAL_API_KEY=your_api_key_here
